{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import used libraries\n",
    "import keras\n",
    "import cv2\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, Lambda, Cropping2D, Input, Activation, MaxPool2D, merge\n",
    "from keras.layers.merge import add\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and display driving log\n",
    "with open('config.json') as config_file:    \n",
    "    config_data = json.load(config_file)\n",
    "print(\"Data path: {}\".format(config_data['data_path']))\n",
    "\n",
    "\n",
    "path = config_data['data_path']\n",
    "file = config_data['driving_log_file']\n",
    "driving_log = pd.read_csv(path + file)\n",
    "driving_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store all images as a numpy array\n",
    "nb_images = 10 # len(driving_log)\n",
    "images = []\n",
    "labels = []\n",
    "camera_names     = ('center', 'left', 'right')\n",
    "# Initalize offsets of the steering angle for center, left and right images\n",
    "steering_offsets = dict({key:val for key,val in zip(camera_names, [0, 0.2, -0.2])})\n",
    "\n",
    "if not os.path.exists(path + config_data['pickle_file']):\n",
    "    for camera in camera_names:\n",
    "        print(\"Load '{}' images\".format(camera))\n",
    "        labels.append((driving_log['steering'][0:nb_images].values.reshape(-1,1) + steering_offsets[camera]))\n",
    "        for row in tqdm(range(0, nb_images), unit=' images'):\n",
    "            img = cv2.imread(path + str.replace(driving_log[camera][row], ' ', ''))\n",
    "            images.append(np.array(img))\n",
    "\n",
    "    for image in images.copy():\n",
    "        images.append(np.fliplr(image))\n",
    "    for label in labels.copy():\n",
    "        labels.append(-1*label)\n",
    "        \n",
    "    images  = np.stack(images)#.reshape(-1, 160, 320, 3)\n",
    "    labels  = np.concatenate(labels)\n",
    "    image_shape = images.shape[1::]\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "    \n",
    "    # Split dataset to train, test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "    # Save as pickle file\n",
    "    print(\"Save data to file: '{}'.\".format(config_data['pickle_file']))\n",
    "    with open(path + config_data['pickle_file'], 'wb') as f: \n",
    "        pickle.dump([X_train, X_test, y_train, y_test], f)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Load data from file: '{}'.\".format(config_data['pickle_file']))\n",
    "    with open(path + config_data['pickle_file'], 'rb') as f: \n",
    "        X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize labels\n",
    "plt.plot(y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_of = lambda x: x.shape[0] * x.shape[1] \n",
    "# Visualize random image\n",
    "print(\"Number of images: 3x{} (center, left, right)\".format(len(driving_log)))\n",
    "\n",
    "img = X_train[0,::]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(np.fliplr(img))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "r   = 100.0 / img.shape[1]\n",
    "dim = (100, int(img.shape[0] * r))\n",
    "dim = (64, 32)\n",
    "# perform the actual resizing of the image and show it\n",
    "resized = cv2.resize(img, dim, interpolation=cv2.INTER_CUBIC)\n",
    "print(resized.shape)\n",
    "plt.imshow(resized)\n",
    "plt.show()\n",
    "print(size_of(img))\n",
    "print(size_of(resized))\n",
    "print(\"Ratio: {}\".format((size_of(img)/size_of(resized))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Inception Network ???  [Inception Network ??? Paper](http://arxiv.org/pdf/1602.07261v1.pdf) in Keras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "def conv_block(x, nb_filters, kernel_size=(3,3), strides=1):\n",
    "\n",
    "    x1 = Convolution2D(nb_filters, kernel_size, strides=strides, padding='same')(x)\n",
    "    #x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    \n",
    "    return x1\n",
    "\n",
    "def res_conv_block(x, kernel_size=(3,3)):\n",
    "    nb_filters = keras.backend.int_shape(x)[3]\n",
    "    x1 = Convolution2D(nb_filters, kernel_size=(1,1), padding='same')(x)\n",
    "    x1 = Convolution2D(nb_filters, kernel_size, padding='same')(x1)\n",
    "    #x1 = BatchNormalization()(x1)\n",
    "    out = add([x, x1])\n",
    "    \n",
    "    return Activation('relu')(out)\n",
    "\n",
    "def inception_A(x):\n",
    "    nb_filters1 = 32\n",
    "    nb_filters2 = keras.backend.int_shape(x)[3]\n",
    "    \n",
    "    x1 = Convolution2D(nb_filters1, kernel_size=(1,1), padding='same')(x)\n",
    "    \n",
    "    x2 = Convolution2D(nb_filters1, kernel_size=(1,1), padding='same')(x)\n",
    "    x2 = Convolution2D(nb_filters1, kernel_size=(3,3), padding='same')(x2)\n",
    "    \n",
    "    x3 = Convolution2D(nb_filters1, kernel_size=(1,1), padding='same')(x)\n",
    "    x3 = Convolution2D(nb_filters1, kernel_size=(3,3), padding='same')(x3)\n",
    "    x3 = Convolution2D(nb_filters1, kernel_size=(3,3), padding='same')(x3)\n",
    "    \n",
    "    x123 = concatenate([x1, x2, x3])\n",
    "    x123 = Convolution2D(nb_filters2, kernel_size=(1,1), padding='same')(x123)\n",
    "    \n",
    "    out = add([x, x123])\n",
    "    return Activation('relu')(out)\n",
    "\n",
    "def reduction_A(x, filter_bank={'k':192,'l':224,'m':256,'n':384}):\n",
    "    x1 = Convolution2D(filter_bank['k'], kernel_size=(1,1), padding='same')(x)\n",
    "    x1 = Convolution2D(filter_bank['l'], kernel_size=(3,3), padding='same')(x1)\n",
    "    x1 = Convolution2D(filter_bank['m'], kernel_size=(3,3), padding='same', strides=2)(x1)\n",
    "    \n",
    "    x2 = Convolution2D(filter_bank['n'], kernel_size=(3,3), padding='same', strides=2)(x)\n",
    "    \n",
    "    x3 = MaxPool2D(strides=2)(x)\n",
    "    \n",
    "    return concatenate([x1, x2, x3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = Input((160, 320, 3))\n",
    "x      = conv_block(init, 32)\n",
    "x      = res_conv_block(x)\n",
    "x      = conv_block(x, 64)\n",
    "x      = inception_A(x)\n",
    "x      = reduction_A(x, filter_bank={'k':24,'l':32,'m':48,'n':64})\n",
    "x      = conv_block(x, 32, strides=2)\n",
    "x      = conv_block(x, 32, strides=2)\n",
    "x      = conv_block(x, 32, strides=2)\n",
    "x      = conv_block(x, 32, strides=2)\n",
    "x      = Flatten()(x)\n",
    "x      = Dense(activation='relu', units=10)(x)\n",
    "out    = Dense(units=1, use_bias=True)(x)\n",
    "model1 = Model(init, out, name='Inception-v4')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=image_shape))\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=64, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=128, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=32, activation='relu', strides=1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "batch_size = 3\n",
    "epochs = 1\n",
    "\n",
    "model1.compile(loss='mse',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "t = now()\n",
    "model1.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "print('Training time: %s' % (now() - t))\n",
    "score = model1.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
