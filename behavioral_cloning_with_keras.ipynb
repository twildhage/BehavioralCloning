{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import used libraries\n",
    "import keras\n",
    "import cv2\n",
    "import datetime\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, Dropout, Lambda, Cropping2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and display driving log\n",
    "with open('config.json') as config_file:    \n",
    "    config_data = json.load(config_file)\n",
    "print(\"Data path: {}\".format(config_data['data_path']))\n",
    "\n",
    "\n",
    "path = config_data['data_path']\n",
    "file = config_data['driving_log_file']\n",
    "driving_log = pd.read_csv(path + file)\n",
    "driving_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store all images as a numpy array\n",
    "nb_images = 100 # len(driving_log)\n",
    "images = []\n",
    "labels = []\n",
    "camera_names     = ('center', 'left', 'right')\n",
    "# Initalize offsets of the steering angle for center, left and right images\n",
    "steering_offsets = dict({key:val for key,val in zip(camera_names, [0, 0.2, -0.2])})\n",
    "\n",
    "if not os.path.exists(path + config_data['pickle_file']):\n",
    "    for camera in camera_names:\n",
    "        print(\"Load '{}' images\".format(camera))\n",
    "        labels.append((driving_log['steering'][0:nb_images].values.reshape(-1,1) + steering_offsets[camera]))\n",
    "        for row in tqdm(range(0, nb_images), unit=' images'):\n",
    "            img = cv2.imread(path + str.replace(driving_log[camera][row], ' ', ''))\n",
    "            images.append(np.array(img))\n",
    "\n",
    "    for image in images.copy():\n",
    "        images.append(np.fliplr(image))\n",
    "    for label in labels.copy():\n",
    "        labels.append(-1*label)\n",
    "        \n",
    "    images  = np.stack(images)#.reshape(-1, 160, 320, 3)\n",
    "    labels  = np.concatenate(labels)\n",
    "    image_shape = images.shape[1::]\n",
    "    images, labels = shuffle(images, labels, random_state=42)\n",
    "    \n",
    "    # Split dataset to train, test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "    # Save as pickle file\n",
    "    print(\"Save data to file: '{}'.\".format(config_data['pickle_file']))\n",
    "    with open(path + config_data['pickle_file'], 'wb') as f: \n",
    "        pickle.dump([X_train, X_test, y_train, y_test], f)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Load data from file: '{}'.\".format(config_data['pickle_file']))\n",
    "    with open(path + config_data['pickle_file'], 'rb') as f: \n",
    "        X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize labels\n",
    "plt.plot(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size_of = lambda x: x.shape[0] * x.shape[1] \n",
    "# Visualize random image\n",
    "print(\"Number of images: 3x{} (center, left, right)\".format(len(driving_log)))\n",
    "\n",
    "img = images[0,::]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "plt.imshow(np.fliplr(img))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "r   = 100.0 / img.shape[1]\n",
    "dim = (100, int(img.shape[0] * r))\n",
    "dim = (64, 32)\n",
    "# perform the actual resizing of the image and show it\n",
    "resized = cv2.resize(img, dim, interpolation=cv2.INTER_CUBIC)\n",
    "print(resized.shape)\n",
    "plt.imshow(resized)\n",
    "plt.show()\n",
    "print(size_of(img))\n",
    "print(size_of(resized))\n",
    "print(\"Ratio: {}\".format((size_of(img)/size_of(resized))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255) - 0.5, input_shape=image_shape))\n",
    "model.add(Cropping2D(cropping=((50,20), (0,0))))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=32, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=64, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(3,3), filters=128, activation='relu', strides=2))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=64, activation='relu', strides=1))\n",
    "model.add(Conv2D(kernel_size=(1,7), filters=32, activation='relu', strides=1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "now = datetime.datetime.now\n",
    "batch_size = 30\n",
    "epochs = 2\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "t = now()\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "print('Training time: %s' % (now() - t))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
